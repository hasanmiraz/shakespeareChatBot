{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ca23b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/miraz/.venv/lib/python3.12/site-packages (25.1.1)\n",
      "Requirement already satisfied: transformers in /home/miraz/.venv/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: sentence-transformers in /home/miraz/.venv/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in /home/miraz/.venv/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: accelerate in /home/miraz/.venv/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/miraz/.venv/lib/python3.12/site-packages (0.46.0)\n",
      "Requirement already satisfied: filelock in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/miraz/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/miraz/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/miraz/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/miraz/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/miraz/.venv/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /home/miraz/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/miraz/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /home/miraz/.venv/lib/python3.12/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: psutil in /home/miraz/.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: setuptools in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/miraz/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/miraz/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/miraz/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/miraz/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/miraz/.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/miraz/.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/miraz/.venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/miraz/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/miraz/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install transformers sentence-transformers faiss-cpu accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a1eed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 5621\n",
      "Sample entry: {'Play': 'Henry IV', 'PlayerLine': \"ACT I\\nSCENE I. London. The palace.\\nEnter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others\\n\\nKING HENRY IV: So shaken as we are, so wan with care,\\nFind we a time for frighted peace to pant,\\nAnd breathe short-winded accents of new broils\\nTo be commenced in strands afar remote.\\nNo more the thirsty entrance of this soil\\nShall daub her lips with her own children's blood,\\nNor more shall trenching war channel her fields,\\nNor bruise her flowerets with the armed hoofs\\nOf hostile paces: those opposed eyes,\\nWhich, like the meteors of a troubled heaven,\\nAll of one nature, of one substance bred,\\nDid lately meet in the intestine shock\\nAnd furious close of civil butchery\\nShall now, in mutual well-beseeming ranks,\\nMarch all one way and be no more opposed\\nAgainst acquaintance, kindred and allies:\", 'Act': '1', 'Scene': '1', 'Speakers': ['KING HENRY IV'], 'firstLine': '1', 'lastLine': '16', 'CharactersPresent': ['LORD JOHN OF LANCASTER', 'EARL WESTMORELAND', 'SIR WALTER BLUNT', 'KING HENRY']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./content/shakespeare_chunked.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_chunks = json.load(f)\n",
    "\n",
    "print(f\"Total chunks: {len(raw_chunks)}\")\n",
    "print(\"Sample entry:\", raw_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfc19f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 5621 documents.\n",
      "Example: {\n",
      "    \"id\": \"chunk_0\",\n",
      "    \"text\": \"ACT I\\nSCENE I. London. The palace.\\nEnter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others\\nKING HENRY IV: So shaken as we are, so wan with care,\\nFind we a time for frighted peace to pant,\\nAnd breathe short-winded accents of new broils\\nTo be commenced in strands afar remote.\\nNo more the thirsty entrance of this soil\\nShall daub her lips with her own children's blood,\\nNor more shall trenching war channel her fields,\\nNor bruise her flowerets with the armed hoofs\\nOf hostile paces: those opposed eyes,\\nWhich, like the meteors of a troubled heaven,\\nAll of one nature, of one substance bred,\\nDid lately meet in the intestine shock\\nAnd furious close of civil butchery\\nShall now, in mutual well-beseeming ranks,\\nMarch all one way and be no more opposed\\nAgainst acquaintance, kindred and allies:\",\n",
      "    \"metadata\": {\n",
      "        \"play\": \"Henry IV\",\n",
      "        \"act\": \"1\",\n",
      "        \"scene\": \"1\",\n",
      "        \"firstLine\": \"1\",\n",
      "        \"lastLine\": \"16\",\n",
      "        \"characters present\": \"LORD JOHN OF LANCASTER, EARL WESTMORELAND, SIR WALTER BLUNT, KING HENRY\",\n",
      "        \"speakers\": \"KING HENRY IV\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def normalize(text: str) -> str:\n",
    "    return \"\\n\".join([line.strip() for line in text.strip().splitlines() if line.strip()])\n",
    "\n",
    "documents = []\n",
    "for idx, chunk in enumerate(raw_chunks):\n",
    "    doc_id = f\"chunk_{idx}\"\n",
    "    documents.append({\n",
    "        \"id\": doc_id,\n",
    "        \"text\": normalize(chunk.get(\"PlayerLine\", \"\")),\n",
    "        \"metadata\": {\n",
    "            \"play\": chunk.get(\"Play\", \"\"),\n",
    "            \"act\": chunk.get(\"Act\", \"\"),\n",
    "            \"scene\": chunk.get(\"Scene\", \"\"),\n",
    "            \"firstLine\": chunk.get(\"firstLine\", \"\"),\n",
    "            \"lastLine\": chunk.get(\"lastLine\", \"\"),\n",
    "            \"characters present\": \", \".join(chunk.get(\"CharactersPresent\", [])),\n",
    "            \"speakers\": \", \".join(chunk.get(\"Speakers\", []))\n",
    "        }\n",
    "    })\n",
    "\n",
    "print(f\"Built {len(documents)} documents.\")\n",
    "print(\"Example:\", json.dumps(documents[0], indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd59ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# texts = [doc[\"text\"] for doc in documents]\n",
    "# embeddings = embedder.encode(\n",
    "#     texts,\n",
    "#     batch_size=32,\n",
    "#     show_progress_bar=True,\n",
    "#     convert_to_numpy=True\n",
    "# )\n",
    "\n",
    "# print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "# Save to disk (these will be gone when session is reseted)\n",
    "# np.save(\"/content/shakespeare_chunked_embeddings.npy\", embeddings)\n",
    "with open(\"./content/shakespeare_chunked_emb.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(documents, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ba44ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed vectors count: 5621\n",
      "FAISS index saved.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.load(\"./content/shakespeare_chunked_embeddings.npy\")\n",
    "D = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(D)\n",
    "index.add(embeddings.astype(\"float32\"))\n",
    "\n",
    "print(\"Indexed vectors count:\", index.ntotal)\n",
    "\n",
    "faiss.write_index(index, \"./content/shakespeare_chunked_index.bin\")\n",
    "print(\"FAISS index saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f37b0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [01:57<00:00, 29.26s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with 4-bit quantization. Device(s): cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"Qwen/Qwen1.5-7B-Chat\"\n",
    "\n",
    "# Configure 4-bit quantization via bitsandbytes for free gpu size\n",
    "# todo: i think i can increase it a bit\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True\n",
    "\n",
    "    # load_in_8bit=True,\n",
    "    # bnb_8bit_compute_dtype=torch.float16,\n",
    "    # bnb_8bit_quant_type=\"nf8\",\n",
    "    # bnb_8bit_use_double_quant=True\n",
    "\n",
    "    # load_in_16bit=True,\n",
    "    # bnb_16bit_compute_dtype=torch.float32,\n",
    "    # bnb_16bit_quant_type=\"nf16\",\n",
    "    # bnb_16bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"Model loaded with 4-bit quantization. Device(s):\", model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c585de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index, metadata, and embeddings reloaded. Total vectors: 5621\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# same here, file will be removed when session resets\n",
    "index = faiss.read_index(\"./content/shakespeare_chunked_index.bin\")\n",
    "with open(\"./content/shakespeare_chunked_emb.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    documents = json.load(f)\n",
    "embeddings = np.load(\"./content/shakespeare_chunked_embeddings.npy\")\n",
    "\n",
    "print(\"Index, metadata, and embeddings reloaded. Total vectors:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae7f23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def embed_query(query: str):\n",
    "    vec = embedder.encode([query], convert_to_numpy=True)\n",
    "    return vec.astype(\"float32\")\n",
    "\n",
    "def retrieve_top_k(query: str, k: int = 5):\n",
    "    print(query)\n",
    "    q_vec = embed_query(query)\n",
    "    distances, indices = index.search(q_vec, k)\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        doc = documents[idx]\n",
    "        results.append({\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"text\": doc[\"text\"],\n",
    "            \"metadata\": doc[\"metadata\"],\n",
    "            \"score\": float(dist)\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def build_prompt(retrieved_chunks, user_question, style=\"shake\"):\n",
    "    if style == \"shake\":\n",
    "        tone_instruction = \"Respond in Shakespearean English, quoting from these passages.\"\n",
    "    else:\n",
    "        tone_instruction = \"Respond clearly as a Shakespeare expert, quoting from these passages.\"\n",
    "\n",
    "    header = f\"You are a Shakespeare expert. {tone_instruction}\\n\\n\"\n",
    "    passages = \"\"\n",
    "    for i, chunk in enumerate(retrieved_chunks, start=1):\n",
    "        passages += f\"[Passage {i}]\\n{chunk['text']}\\n\\n\"\n",
    "    question_block = f\"### Question:\\n{user_question}\\n\\n### Answer:\\n\"\n",
    "    return header + passages + question_block\n",
    "\n",
    "def generate_answer(prompt: str, max_new_tokens: int = 300, temperature: float = 0.8):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    generated = output_ids[0][ inputs[\"input_ids\"].shape[1]: ]\n",
    "    return tokenizer.decode(generated, skip_special_tokens=True).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "570e2c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does Hamlet not kill Claudius, please use source from Play: Hamlet Act 3, Scene 3?\n",
      "Retrieved passages (top 5):\n",
      " 1. [score 0.54] HAMLET: ACT III SCENE I. A room in the castle. Enter KING CLAUDIUS, QUEEN GERTRUDE, POLONIUS, OPHELIA, ROSENCRANTZ, and GUILDENSTERN KING CLAUDIUS: And can you, by no drift of circumstance, Get from h...\n",
      " 2. [score 0.59] KING CLAUDIUS: Exeunt ROSENCRANTZ and GUILDENSTERN And, England, if my love thou hold'st at aught-- As my great power thereof may give thee sense, Since yet thy cicatrice looks raw and red After the D...\n",
      " 3. [score 0.59] KING CLAUDIUS: Time qualifies the spark and fire of it. There lives within the very flame of love A kind of wick or snuff that will abate it, And nothing is at a like goodness still, For goodness, gro...\n",
      " 4. [score 0.60] HAMLET: SCENE III. Another room in the castle. Enter KING CLAUDIUS, attended KING CLAUDIUS: I have sent to seek him, and to find the body. How dangerous is it that this man goes loose! Yet must not we...\n",
      " 5. [score 0.61] HAMLET: Treachery! Seek it out. LAERTES: It is here, Hamlet: Hamlet, thou art slain, No medicine in the world can do thee good, In thee there is not half an hour of life, The treacherous instrument is...\n",
      "\n",
      "Generating answer...\n",
      "\n",
      "=== ShakespeareBot Answer ===\n",
      "\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "def user_query(user_question: str):\n",
    "  top_chunks = retrieve_top_k(user_question, k=5)\n",
    "  print(\"Retrieved passages (top 5):\")\n",
    "  for i, c in enumerate(top_chunks, start=1):\n",
    "      snippet = c[\"text\"].replace(\"\\n\", \" \")[:200]\n",
    "      print(f\" {i}. [score {c['score']:.2f}] {snippet}...\")\n",
    "\n",
    "  prompt = build_prompt(top_chunks, user_question, style=\"shake\")\n",
    "\n",
    "  print(\"\\nGenerating answer...\\n\")\n",
    "  answer = generate_answer(prompt, max_new_tokens=200, temperature=0.8)\n",
    "  print(\"=== ShakespeareBot Answer ===\")\n",
    "  print(answer)\n",
    "  print(\"#\"*50)\n",
    "\n",
    "# user_query(\"Why does Hamlet kill Polonius?\")\n",
    "\n",
    "user_query(\"Why does Hamlet not kill Claudius, please use source from Play: Hamlet Act 3, Scene 3?\")\n",
    "# user_query(\"How and why does Hamlet get his friends Rosencrantz and Guildenstern killed?\")\n",
    "# user_query(\"How did Ophelia die?\")\n",
    "# user_query(\"Why was Hamlet angry with his mother Gertrude?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33610c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
